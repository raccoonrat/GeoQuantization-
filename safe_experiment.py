#!/usr/bin/env python3
"""
å®‰å…¨å®éªŒè„šæœ¬ - é¿å…GPUå†…å­˜ä¸è¶³å’ŒWSLå´©æºƒ
"""

import os
import sys
import gc
import psutil
import logging
from pathlib import Path

# è®¾ç½®ç¼–ç 
os.environ['PYTHONIOENCODING'] = 'utf-8'
os.environ['LANG'] = 'en_US.UTF-8'
os.environ['LC_ALL'] = 'en_US.UTF-8'

# å¼ºåˆ¶CPUæ¨¡å¼ - é¿å…GPUå†…å­˜é—®é¢˜
os.environ['CUDA_VISIBLE_DEVICES'] = ''  # ç¦ç”¨GPU
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:32'
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'

# è®¾ç½®HuggingFaceé•œåƒ
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'
os.environ['HF_HUB_DISABLE_PROGRESS_BARS'] = '1'
os.environ['HF_HUB_OFFLINE'] = '0'

# è®¾ç½®ç¼“å­˜ç›®å½•
cache_dir = os.path.join(os.getcwd(), 'hf_cache')
os.environ['HF_HOME'] = cache_dir
os.makedirs(cache_dir, exist_ok=True)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('safe_experiment.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def check_memory():
    """æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    memory = psutil.virtual_memory()
    logger.info(f"å†…å­˜ä½¿ç”¨: {memory.percent}% ({memory.used // (1024**3)}GB / {memory.total // (1024**3)}GB)")
    
    if memory.percent > 85:
        logger.warning("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå¯èƒ½å¯¼è‡´WSLå´©æºƒ")
        return False
    
    return True

def safe_model_test():
    """å®‰å…¨æ¨¡å‹æµ‹è¯•"""
    logger.info("å¼€å§‹å®‰å…¨æ¨¡å‹æµ‹è¯•...")
    
    try:
        import torch
        logger.info(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        logger.info(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
        logger.info(f"è®¾å¤‡: {'CPU' if not torch.cuda.is_available() else 'GPU'}")
        
        # å¼ºåˆ¶ä½¿ç”¨CPU
        device = torch.device('cpu')
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
        
        from transformers import AutoTokenizer, AutoModelForCausalLM
        
        # ä½¿ç”¨æœ€å°æ¨¡å‹
        model_name = "facebook/opt-125m"
        logger.info(f"åŠ è½½æ¨¡å‹: {model_name}")
        
        # åŠ è½½tokenizer
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        
        # åŠ è½½æ¨¡å‹ - ä½¿ç”¨float32é¿å…å†…å­˜é—®é¢˜
        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype=torch.float32,  # ä½¿ç”¨float32
            device_map="cpu",  # å¼ºåˆ¶CPU
            low_cpu_mem_usage=True  # ä½å†…å­˜ä½¿ç”¨
        )
        
        logger.info("æ¨¡å‹åŠ è½½æˆåŠŸ!")
        
        # ç®€å•æµ‹è¯• - ä½¿ç”¨æœ€å°è¾“å…¥
        test_text = "Hello"
        inputs = tokenizer(test_text, return_tensors="pt")
        
        with torch.no_grad():
            outputs = model.generate(
                inputs.input_ids,
                max_length=10,  # æœ€å°é•¿åº¦
                num_return_sequences=1,
                do_sample=False,
                pad_token_id=tokenizer.eos_token_id
            )
        
        result = tokenizer.decode(outputs[0], skip_special_tokens=True)
        logger.info(f"æµ‹è¯•ç»“æœ: {result}")
        
        # æ¸…ç†å†…å­˜
        del model, tokenizer, outputs
        gc.collect()
        
        return True
        
    except Exception as e:
        logger.error(f"æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def safe_geometry_test():
    """å®‰å…¨å‡ ä½•åˆ†ææµ‹è¯•"""
    logger.info("å¼€å§‹å®‰å…¨å‡ ä½•åˆ†ææµ‹è¯•...")
    
    try:
        import numpy as np
        from sklearn.decomposition import PCA
        from sklearn.cluster import DBSCAN
        
        # åˆ›å»ºå°è§„æ¨¡æ¨¡æ‹Ÿæ•°æ®
        np.random.seed(42)
        data = np.random.randn(50, 5)  # å‡å°‘æ•°æ®é‡
        
        # PCAé™ç»´
        pca = PCA(n_components=3)  # å‡å°‘ç»„ä»¶æ•°
        reduced_data = pca.fit_transform(data)
        
        # DBSCANèšç±»
        clustering = DBSCAN(eps=0.5, min_samples=2)  # å‡å°‘æœ€å°æ ·æœ¬æ•°
        labels = clustering.fit_predict(reduced_data)
        
        n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
        logger.info(f"èšç±»ç»“æœ: {n_clusters} ä¸ªç°‡")
        
        # æ¸…ç†å†…å­˜
        del data, reduced_data, labels
        gc.collect()
        
        return True
        
    except Exception as e:
        logger.error(f"å‡ ä½•åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return False

def safe_noise_test():
    """å®‰å…¨å™ªå£°æµ‹è¯•"""
    logger.info("å¼€å§‹å®‰å…¨å™ªå£°æµ‹è¯•...")
    
    try:
        import torch
        import numpy as np
        
        # åˆ›å»ºå°è§„æ¨¡æµ‹è¯•æ•°æ®
        test_data = torch.randn(10, 5)  # å°è§„æ¨¡æ•°æ®
        
        # æµ‹è¯•ä¸åŒå™ªå£°æ°´å¹³
        noise_levels = [0.0, 0.01, 0.1]
        
        for noise_level in noise_levels:
            noise = torch.randn_like(test_data) * noise_level
            noisy_data = test_data + noise
            
            # è®¡ç®—å˜åŒ–
            change = torch.mean(torch.abs(noisy_data - test_data)).item()
            logger.info(f"å™ªå£°æ°´å¹³ {noise_level}: å¹³å‡å˜åŒ– {change:.4f}")
        
        # æ¸…ç†å†…å­˜
        del test_data, noise, noisy_data
        gc.collect()
        
        return True
        
    except Exception as e:
        logger.error(f"å™ªå£°æµ‹è¯•å¤±è´¥: {e}")
        return False

def save_safe_results():
    """ä¿å­˜å®‰å…¨å®éªŒç»“æœ"""
    logger.info("ä¿å­˜å®‰å…¨å®éªŒç»“æœ...")
    
    try:
        import pandas as pd
        import json
        
        results = {
            "timestamp": str(pd.Timestamp.now()),
            "model_test": "passed",
            "geometry_test": "passed", 
            "noise_test": "passed",
            "memory_usage": "optimized",
            "device": "CPU",
            "model_size": "small"
        }
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path("prm_outputs")
        output_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜ç»“æœ
        with open(output_dir / "safe_results.json", "w") as f:
            json.dump(results, f, indent=2)
        
        # åˆ›å»ºCSVæŠ¥å‘Š
        df = pd.DataFrame([results])
        df.to_csv(output_dir / "safe_results.csv", index=False)
        
        logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")
        
    except Exception as e:
        logger.error(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸ›¡ï¸ å®‰å…¨å®éªŒå¼€å§‹")
    logger.info("=" * 50)
    
    # æ£€æŸ¥å†…å­˜
    if not check_memory():
        logger.warning("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œä½†ç»§ç»­è¿è¡Œ...")
    
    try:
        # å®‰å…¨æ¨¡å‹æµ‹è¯•
        if not safe_model_test():
            logger.error("æ¨¡å‹æµ‹è¯•å¤±è´¥")
            return 1
        
        # å®‰å…¨å‡ ä½•åˆ†ææµ‹è¯•
        if not safe_geometry_test():
            logger.error("å‡ ä½•åˆ†ææµ‹è¯•å¤±è´¥")
            return 1
        
        # å®‰å…¨å™ªå£°æµ‹è¯•
        if not safe_noise_test():
            logger.error("å™ªå£°æµ‹è¯•å¤±è´¥")
            return 1
        
        # ä¿å­˜ç»“æœ
        save_safe_results()
        
        logger.info("âœ… å®‰å…¨å®éªŒå®Œæˆ!")
        logger.info("æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ŒWSLåº”è¯¥ä¸ä¼šå´©æºƒ")
        
        return 0
        
    except Exception as e:
        logger.error(f"å®éªŒå¤±è´¥: {e}")
        return 1
    finally:
        # æ¸…ç†å†…å­˜
        gc.collect()

if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"è‡´å‘½é”™è¯¯: {e}")
        sys.exit(1)
