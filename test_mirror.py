#!/usr/bin/env python3
"""
æµ‹è¯•HuggingFaceé•œåƒé…ç½®
"""

import os
import sys
import requests

def test_mirror_connection():
    """æµ‹è¯•é•œåƒè¿æ¥"""
    print("æµ‹è¯•HuggingFaceé•œåƒè¿æ¥...")
    
    mirrors = [
        "https://hf-mirror.com",
        "https://huggingface.co"
    ]
    
    for mirror in mirrors:
        try:
            print(f"æµ‹è¯• {mirror}...")
            response = requests.get(f"{mirror}/api/models", timeout=10)
            if response.status_code == 200:
                print(f"âœ… {mirror}: è¿æ¥æˆåŠŸ")
                return mirror
            else:
                print(f"âš ï¸  {mirror}: çŠ¶æ€ç  {response.status_code}")
        except Exception as e:
            print(f"âŒ {mirror}: {e}")
    
    return None

def test_model_download():
    """æµ‹è¯•æ¨¡å‹ä¸‹è½½"""
    print("\næµ‹è¯•æ¨¡å‹ä¸‹è½½...")
    
    try:
        from transformers import AutoTokenizer
        
        # è®¾ç½®é•œåƒ
        os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
        os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'
        os.environ['HF_HUB_DISABLE_PROGRESS_BARS'] = '1'
        
        # æµ‹è¯•ä¸‹è½½å°æ¨¡å‹
        model_name = "facebook/opt-125m"
        print(f"æ­£åœ¨ä¸‹è½½æ¨¡å‹: {model_name}")
        
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        print("âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸ!")
        
        # æµ‹è¯•åˆ†è¯
        test_text = "Hello, world!"
        tokens = tokenizer(test_text, return_tensors="pt")
        print(f"âœ… åˆ†è¯æµ‹è¯•æˆåŠŸ: {tokens.input_ids.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
        return False

def test_dataset_download():
    """æµ‹è¯•æ•°æ®é›†ä¸‹è½½"""
    print("\næµ‹è¯•æ•°æ®é›†ä¸‹è½½...")
    
    try:
        from datasets import load_dataset
        
        # è®¾ç½®é•œåƒ
        os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
        os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'
        os.environ['HF_HUB_DISABLE_PROGRESS_BARS'] = '1'
        
        # æµ‹è¯•ä¸‹è½½å°æ•°æ®é›†
        dataset_name = "wikitext"
        subset = "wikitext-2-raw-v1"
        print(f"æ­£åœ¨ä¸‹è½½æ•°æ®é›†: {dataset_name}/{subset}")
        
        dataset = load_dataset(dataset_name, subset, split='train[:10]')
        print(f"âœ… æ•°æ®é›†ä¸‹è½½æˆåŠŸ! æ ·æœ¬æ•°: {len(dataset)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†ä¸‹è½½å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ HuggingFaceé•œåƒæµ‹è¯•å·¥å…·")
    print("=" * 50)
    
    # æµ‹è¯•é•œåƒè¿æ¥
    mirror = test_mirror_connection()
    
    if not mirror:
        print("âŒ æ‰€æœ‰é•œåƒéƒ½æ— æ³•è¿æ¥")
        return 1
    
    # æµ‹è¯•æ¨¡å‹ä¸‹è½½
    model_ok = test_model_download()
    
    # æµ‹è¯•æ•°æ®é›†ä¸‹è½½
    dataset_ok = test_dataset_download()
    
    print("\n" + "=" * 50)
    
    if model_ok and dataset_ok:
        print("âœ… é•œåƒé…ç½®æµ‹è¯•æˆåŠŸ!")
        print(f"æ¨èé•œåƒ: {mirror}")
        print("ç°åœ¨å¯ä»¥è¿è¡Œå®éªŒ:")
        print("  python run_with_mirror.py")
    else:
        print("âŒ é•œåƒé…ç½®æµ‹è¯•å¤±è´¥")
        print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
    
    return 0 if (model_ok and dataset_ok) else 1

if __name__ == "__main__":
    sys.exit(main())
