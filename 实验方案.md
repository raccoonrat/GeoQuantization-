从零到一的实验方案
===========================

下面给出一个可复现、分阶段、量化且带统计检验的实验方案，目标是**基于几何意义**把模型权重/激活中的离群点分为 **功能型（functional）**、**敏感型（sensitive）** 与 **混合型（both）**，并用实验统计验证它们在精度（∆PPL）与隐私（∆MIA AUC）上的不同响应模式。方案直接以你上传的 GeoQ.pdf 中提出的 FSGD / PRM 思路为骨干，并把实现细节、可测指标、阈值与统计流程具体化以便一键复现与论文级评审。

* * *

实验总体设计（3 个阶段）
-------------

1. **数据与模型准备（Calibration & Baselines）** — 构建校准集，加载目标模型并测量基线精度/隐私。

2. **几何探测与子空间划分（FSGD 实施）** — 用 Hessian / 激活稀疏度 / UMAP 聚类等方法标注每层参数的三类子空间（Wfunc/Wsens/Wboth）。

3. **扰动响应映射（PRM）与统计验证** — 在每个子空间施加梯度噪声（σ 从 0 → 1e-3），记录 ∆PPL 与 ∆AUC，绘制 PRM 相图并做显著性检验以验证几何可分离性。

* * *

1) 数据、模型与基线

-----------

* **模型候选（示例）**：Llama-2-7B（用于层级指标实验）和 Llama-3-8B（用于大规模验证），两者均在论文中作为示例。

* **校准与评估数据**：
  
  * 校准集用于构造基矩阵 B = sX：采样自然语言校准句子（512–2048 tokens per model），为每层准备 `k` 个子集（建议 k=10，n=100 每子集 做鲁棒性测试）。
  
  * 评估集：标准语言建模验证集（用于 PPL），以及构造的成员推断测试集（用于 MIA：包含 member / non-member 样本对）。

* **基线测量**：记录全精度模型的 PPL 与 MIA AUC（用于后续 ∆PPL、∆AUC 计算）。

* * *

2) 幾何探测器与子空间划分（FSGD 具体步骤）

-------------------------

目标：把单层的参数/通道划分成 `Wfunc`、`Wsens`、`Wboth` 三个子空间（按文中 FSGD 定义）。

步骤细化（按层执行）：

1. **Hessian 局部谱估计**
   
   * 使用 Lanczos / power-iteration 快速估算顶层 few 个特征值与特征向量（建议取 Top 1% 最大特征值或前 50 个特征向量，具体按 c 决定）。用于局部曲率与主成分对齐计算。

2. **主成分对齐（功能性指示器）**
   
   * 对每个权重向量或参数分组，计算其与 Hessian 顶层主成分的投影范数 / 余弦相似度。阈值建议：cos ≥ 0.7 标记为“高度对齐（功能候选）”。

3. **激活稀疏度（敏感型指示器）**
   
   * 在校准/验证输入上记录该参数（或通道）被显著激活的比例；若激活稀疏度 ≥ 0.9，视为“稀疏激活（敏感候选）”。

4. **流形学习 + 聚类（可视化 & 辅助判定）**
   
   * 把每个参数的低维表示（例如把参数向量拼接上主成分对齐度、局部曲率、激活稀疏度）用 UMAP / t-SNE 降到 2D/3D，做 DBSCAN 聚类并用轮廓系数评估簇分离性（NPR 检验确保降维可信：目标 NPR > 0.7）。簇的拓扑形式帮助确定“离岛”vs“主流形”。

5. **最终划分规则（简单可执行版本）**
   
   * Wfunc：cos ≥ 0.7 且激活稀疏度 < 0.5
   
   * Wsens：cos ≤ 0.3 且激活稀疏度 ≥ 0.9（离岛）
   
   * Wboth：cos ∈ (0.3,0.7) 且局部曲率高（Top 1% 特征值贡献）或同时满足高稀疏度与高对齐  
     （阈值可在 pilot 实验中微调并报告灵敏度分析）。

* * *

3) 扰动响应映射（PRM）实验细节

------------------

* **扰动方法**：对每个子空间 Wi，按元素施加独立高斯噪声 `N(0, σ_i^2)`；σ_i 从 0、1e-6、1e-5、1e-4、1e-3（或更细分）逐步增加。

* **测量**：每个 σi 下计算
  
  * ∆PPL(σi) = PPL(Wi + noise) − PPL(Wi)
  
  * ∆AUC(σi) = AUC(Wi + noise) − AUC(Wi)  
    并重复 m 次（建议 m=5）以估计均值与置信区间。

* **相图与轨迹**：在 ∆PPL（x 轴） vs ∆AUC（y 轴）绘制每个子空间的 PRM 轨迹族；用 KDE 对轨迹簇作聚类并计算簇之间欧氏距离，按论文建议视轨迹间距 ≥ 2σ 为显著分离。

* **预期轨迹模式（用于判定）**：
  
  * Wfunc → 主要沿 x 轴（∆PPL ↑，∆AUC 变化很小）
  
  * Wsens → 主要沿 y 轴（∆AUC ↓，∆PPL ↑ 很小）
  
  * Wboth → 两轴均显著（对角线）  
    这些是论文给出的预期，可作为检验假设的判据。

* * *

4) 量化/格几何工具（用于补充验证）

-------------------

* **格相关指标**：对每层构建基矩阵 `B = sX`，计算条件数 κ(B)、格几何稳定性指数（LSI S）与格正交性缺陷度 η（LOD），检验这些几何指标与量化误差（RE / ∆PPL）之间的相关性（皮尔逊或 Spearman）。论文建议：log(κ(B)) 与 MSE 有强正相关。

* **LLL 预处理实验**：对 η 较高的层尝试 LLL 基约减，观察 η、RE 与 ∆PPL 的改善（论文预期 η 降 ≥30%，RE 降 15–20%）。这用于连接格几何与实际量化改善。

* * *

5) 统计检验与鲁棒性

-----------

* **重复与置信区间**：每个扰动点重复 m 次（m≥5），报告均值 ±95% CI。

* **显著性测试**：对 PRM 轨迹的子空间差异，使用多元 MANOVA（多个 σ 条件下的 ∆PPL 与 ∆AUC 向量），若拒绝等均值假设，再用成对 t-test 或 Wilcoxon 检验（配对）检验 Wfunc vs Wsens 等。校正多重检验（Benjamini–Hochberg）。

* **阈值检验**：论文中给出可操作阈值（∆PPL ≥ 0.3 被视为功能显著，MIA ∆AUC ≥ 0.1 被视为敏感显著）— 在报告中把这些阈值作为“事前定义好的次要判据”，并同时做敏感性分析以展示结论对阈值的稳健性。

* * *

6) 实验产出（要提交/展示的内容）

------------------

* PRM 二维相图（带 KDE / 簇边界）。

* 每层与每子空间的 ∆PPL/∆AUC 曲线 + 置信区间（表格与可下载 CSV）。

* UMAP 可视化图与 NPR 指标（验证降维可靠性）。

* 格几何指标（κ、η、LSI S）与量化误差 (RE) 的相关性热图；对 η 高层的 LLL 实验结果对比。

* 统计检验结果（MANOVA、成对检验、多重检验校正）与结论段。

* * *

7) 风险、限制与备选方案

-------------

* **计算量**：Hessian 局部特征估计、UMAP 与 LLL 约减在大模型上昂贵。缓解：只对采样的层或按重要性排序的 top-k 通道做全量分析；使用随机子集与 Lanczos 近似。

* **降维失真**：用 NPR（邻域保持率）检验并报告；若 NPR < 0.6，需调整 UMAP 参数或基于高维指标直接做判定。

* **MIA 实验设计**：成员推断攻击方法须明确（黑盒 vs 白盒、使用何种统计量）并与社区标准对齐；建议复现 GeoQ 里使用的 MIA 测量流程以保证可比性。

* * *

8) 可复现的最小化试验（pilot recipe，30–60 行 pseudo-code）

----------------------------------------------

（这里给出摘要流程，便于工程化实现）

1. 载入模型（Llama-2-7B），准备校准集 `X_full`。

2. 为每层抽取参数分组（按通道或按列）。

3. 对每层：估算 Hessian top-k 特征向量；计算每个参数的 cos 与激活稀疏度 → 初步标注 Wfunc/Wsens/Wboth。

4. 对每个子空间 Wi：对 σ ∈ {0,1e-6,1e-5,1e-4,1e-3} 重复 m 次：添加噪声 → 评估 PPL 与 MIA AUC → 存档结果。

5. 绘图（PRM）、做 MANOVA 与成对检验、报告结论与灵敏度分析。  
   （如需，我可以把这段 pseudo-code 展开成 Jupyter Notebook + 可运行 Python 代码并生成 CSV/图表——如果你要我现在生成代码，请直接回复“生成 Notebook”。）

* * *

关键引用与依据（来自你上传的论文）
-----------------

* PRM 定义与二轴相图设计（∆PPL, ∆AUC）与轨迹预期。

* FSGD 的子空间定义（主功能流形、离岛、尖峰）及其可观测指标（曲率、Hessian 谱、激活稀疏度）。

* Lattice 指标（κ(B)、LSI S、LOD η）与其与量化误差的关系，以及 LLL 的正则化作用。

* 校准集自助/交叉策略与样本数量建议（k、n）及稳定性检验。

* * *

## 目标

A. “最小化试验”扩成可执行的 Jupyter Notebook（含数据结构、主要函数、示例层的演示）；  
B. 生成一页供顶会审稿用的“方法图表 + PRM 相图示意 + 关键表格（阈值、统计检验）”；  
C. 把实验中的 pseudo-code 展开为详细的 Python 实现（不含模型权重下载权限），包括 Hessian/top-eig 估算与 MIA 实验框架。



A. 最小化试验

```python
# PRM_FSGD_Experiment_Notebook.py
# 从零到一的实验 Notebook（最小可运行版）
# 目标：实现 GeoQ/PRM - 基于几何的功能型 vs 敏感型 outlier 分离实验框架
# 说明：本文件为单文件 Python 实现示例（可直接另存为 .py 或在 notebook 中拆分为 cells）。
# 作者：为你生成的可复现实验骨架（需在本地/服务器上运行，须安装依赖并提供模型权重）

"""
快速说明（请先阅读）
1) 环境建议：Python>=3.10, PyTorch>=2.0, transformers, datasets, scikit-learn, umap-learn, tqdm
   可选：accelerate, bitsandbytes
2) 本 Notebook/Script 不包含任何预训练权重或数据下载；请在运行前确保能访问模型与数据。
3) 运行步骤（建议）：
   - 安装依赖
   - 准备校准集与评估集（脚本包含示例加载函数）
   - 配置 MODEL_NAME 与运行参数
   - 执行 pilot_run() 做小规模验证，再运行 full_experiment()

输出：CSV 文件（每次扰动的结果）、PRM 相图的 PNG、UMAP 可视化 PNG
"""

import os
import math
import json
import random
import time
from dataclasses import dataclass
from typing import List, Tuple, Dict, Any

import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader

# External libs (ensure installed)
from transformers import AutoModelForCausalLM, AutoTokenizer
from datasets import load_dataset
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.cluster import DBSCAN
from sklearn.metrics import silhouette_score
import umap
import matplotlib.pyplot as plt
from tqdm import tqdm

# -----------------------------
# Config
# -----------------------------
@dataclass
class Config:
    model_name: str = "facebook/opt-125m"  # 默认小模型用于 pilot
    device: str = "cuda" if torch.cuda.is_available() else "cpu"
    calib_dataset: str = "wikitext", "wikitext-2-raw-v1"
    calib_samples: int = 200  # pilot 时使用较小样本
    eval_samples: int = 200
    batch_size: int = 8
    seed: int = 42
    topk_eig: int = 50
    noise_sigmas: List[float] = (0.0, 1e-6, 1e-5, 1e-4, 1e-3)
    repeats: int = 3
    output_dir: str = "prm_outputs"

cfg = Config()
os.makedirs(cfg.output_dir, exist_ok=True)

# -----------------------------
# Utilities
# -----------------------------

def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

set_seed(cfg.seed)


def save_json(obj, path):
    with open(path, 'w') as f:
        json.dump(obj, f, indent=2)

# -----------------------------
# Data loading (calibration & eval set)
# -----------------------------

def get_calib_texts(dataset_name: Tuple[str, str], n: int):
    # dataset_name: (hub_name, subset) or str
    ds = load_dataset(dataset_name[0], dataset_name[1], split='train')
    # sample n examples (simple strategy)
    samples = []
    for ex in ds:
        text = ex.get('text') or ex.get('article') or ex.get('content')
        if text and len(text.split()) > 5:
            samples.append(text)
        if len(samples) >= n:
            break
    return samples

# -----------------------------
# Model & hooks: capturing activations & parameter groups
# -----------------------------

class ModelWrapper:
    def __init__(self, model_name: str, device: str = 'cpu'):
        print(f"Loading model {model_name} on {device} ...")
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForCausalLM.from_pretrained(model_name)
        self.model.to(device)
        self.device = device
        self.model.eval()
        # For simplicity, we will focus on Linear layers in transformer blocks
        self.param_groups = self._collect_param_groups()
        print(f"Collected {len(self.param_groups)} param groups")

    def _collect_param_groups(self):
        groups = []
        for name, p in self.model.named_parameters():
            # focus on weight tensors of Linear / Embedding
            if 'weight' in name and p.ndim >= 2:
                groups.append((name, p))
        return groups

    def tokenize(self, texts: List[str], max_length=256):
        return self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=max_length)

    @torch.no_grad()
    def compute_ppl(self, texts: List[str], batch_size=8) -> float:
        # rough PPL estimate using cross-entropy over dataset
        tok = self.tokenize(texts)
        input_ids = tok['input_ids'].to(self.device)
        attention_mask = tok['attention_mask'].to(self.device)
        nll = 0.0
        total = 0
        with torch.no_grad():
            for i in range(0, input_ids.size(0), batch_size):
                ids = input_ids[i:i+batch_size]
                att = attention_mask[i:i+batch_size]
                outputs = self.model(ids, attention_mask=att, labels=ids)
                # outputs.loss is mean across tokens
                batch_nll = outputs.loss.item() * ids.numel()
                nll += batch_nll
                total += ids.numel()
        ppl = math.exp(nll / total)
        return ppl

# -----------------------------
# Approximate top-k eigens via power iteration on Hessian-vector product
# Note: exact Hessian is expensive; we use gradient covariance or fisher approx
# -----------------------------

def approx_top_eigvecs(model: ModelWrapper, calib_texts: List[str], topk=50, device='cpu'):
    # Strategy: compute per-parameter gradient vectors across small batch set
    # then do PCA on stacked gradients to get principal directions (proxy for Hessian eigvecs)
    tokenizer = model.tokenizer
    Gs = []
    model.model.zero_grad()
    for text in tqdm(calib_texts[: max(20, len(calib_texts))], desc='grad-collect'):
        tok = tokenizer(text, return_tensors='pt', truncation=True, max_length=128)
        input_ids = tok['input_ids'].to(device)
        att = tok['attention_mask'].to(device)
        out = model.model(input_ids, attention_mask=att, labels=input_ids)
        loss = out.loss
        grads = torch.autograd.grad(loss, [p for (_, p) in model.param_groups], retain_graph=False, create_graph=False, allow_unused=True)
        # flatten and concatenate grads to 1D
        grad_flat = torch.cat([g.detach().flatten() if g is not None else torch.zeros_like(p).flatten() for ( (_, p), g) in zip(model.param_groups, grads)])
        Gs.append(grad_flat.cpu().numpy())
        model.model.zero_grad()
    G = np.stack(Gs, axis=0)
    # PCA
    G_mean = G.mean(axis=0, keepdims=True)
    Gc = G - G_mean
    u, s, vh = np.linalg.svd(Gc, full_matrices=False)
    vecs = vh[:topk]
    vals = s[:topk]
    return vecs, vals

# -----------------------------
# Activation sparsity / importance per param group
# -----------------------------

def compute_activation_sparsity(model: ModelWrapper, texts: List[str], device='cpu') -> Dict[str, float]:
    # Simple proxy: for modules with outputs -> measure fraction of near-zero activations
    # We'll instrument forward hooks on Linear modules
    activ_counts = {}
    activ_nonzero = {}
    hooks = []

    def make_hook(name):
        def hook(module, inp, out):
            a = out.detach().cpu()
            # consider nonzero if abs > 1e-5
            nonzero = (a.abs() > 1e-5).sum().item()
            total = a.numel()
            activ_nonzero[name] = activ_nonzero.get(name, 0) + nonzero
            activ_counts[name] = activ_counts.get(name, 0) + total
        return hook

    # attach hooks to linear modules
    for name, module in model.model.named_modules():
        if isinstance(module, torch.nn.Linear):
            hooks.append(module.register_forward_hook(make_hook(name)))

    # run a few inputs
    tokenizer = model.tokenizer
    for text in tqdm(texts[:cfg.calib_samples], desc='activ-pass'):
        tok = tokenizer(text, return_tensors='pt', truncation=True, max_length=128)
        input_ids = tok['input_ids'].to(device)
        att = tok['attention_mask'].to(device)
        with torch.no_grad():
            _ = model.model(input_ids, attention_mask=att)

    # remove hooks
    for h in hooks:
        h.remove()

    sparsity = {}
    for k in activ_counts:
        frac = 1.0 - (activ_nonzero[k] / activ_counts[k])
        sparsity[k] = frac
    return sparsity

# -----------------------------
# Param-level features aggregation & clustering (UMAP + DBSCAN)
# -----------------------------

def build_param_feature_matrix(model: ModelWrapper, eigvecs: np.ndarray, sparsity: Dict[str, float]):
    # For each parameter group, compute projection onto eigvecs and attach sparsity
    feats = []
    names = []
    for name, p in model.param_groups:
        names.append(name)
        arr = p.detach().cpu().numpy().flatten()
        # projection onto first few eigvecs (use dot)
        proj = arr.dot(eigvecs.T[:min(eigvecs.shape[0], 20)].T) if eigvecs.size else np.zeros(20)
        # curvature proxy: l2 norm
        curvature = np.linalg.norm(arr)
        sp = sparsity.get(name, 0.0)
        vec = np.concatenate([proj.flatten(), [curvature, sp]])
        feats.append(vec)
    X = np.stack(feats, axis=0)
    return names, X


def cluster_and_label(names: List[str], X: np.ndarray, n_neighbors=15, min_dist=0.1):
    reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, random_state=cfg.seed)
    emb = reducer.fit_transform(X)
    # dbscan clustering
    db = DBSCAN(eps=0.5, min_samples=5).fit(emb)
    labels = db.labels_
    sil = -1.0
    try:
        sil = silhouette_score(emb, labels)
    except Exception:
        pass
    return emb, labels, sil

# -----------------------------
# Partition rule to decide Wfunc, Wsens, Wboth per name
# -----------------------------

def partition_rule(names: List[str], X: np.ndarray, eigvecs: np.ndarray, sparsity: Dict[str, float]):
    # Simple heuristic rules as in plan; returns dict name->label
    labels = {}
    for i, name in enumerate(names):
        sp = sparsity.get(name, 0.0)
        # cos alignment proxy: abs(dot with first eigvec) normalized
        if eigvecs.size:
            arr = X[i, :eigvecs.shape[0]]
            cos = np.mean(np.abs(arr))  # proxy
        else:
            cos = 0.0
        if cos >= 0.7 and sp < 0.5:
            labels[name] = 'Wfunc'
        elif cos <= 0.3 and sp >= 0.9:
            labels[name] = 'Wsens'
        else:
            labels[name] = 'Wboth'
    return labels

# -----------------------------
# Noise injection & evaluation
# -----------------------------

def inject_noise_and_eval(model: ModelWrapper, name_to_mask: Dict[str, str], sigma: float, texts_eval: List[str]):
    # name_to_mask: mapping param_name -> label (we will perturb only params with a given label if specified by caller)
    # This function perturbs params in-place, evaluates PPL, then restores original params
    original = {}
    device = model.device
    for name, p in model.model.named_parameters():
        if name in name_to_mask:
            original[name] = p.data.clone()
            noise = torch.randn_like(p.data) * sigma
            p.data.add_(noise)
    # eval
    ppl = model.compute_ppl(texts_eval, batch_size=cfg.batch_size)
    # placeholder for MIA AUC: user must provide MIA eval pipeline; we put None
    mia_auc = None
    # restore
    for name, p in model.model.named_parameters():
        if name in original:
            p.data.copy_(original[name])
    return ppl, mia_auc

# -----------------------------
# Orchestration: pilot run and full experiment
# -----------------------------

def pilot_run():
    # load model
    mw = ModelWrapper(cfg.model_name, cfg.device)
    # calib data
    calib = get_calib_texts(cfg.calib_dataset, cfg.calib_samples)
    evals = get_calib_texts(cfg.calib_dataset, cfg.eval_samples)
    # baseline ppl
    baseline_ppl = mw.compute_ppl(evals[:50], batch_size=cfg.batch_size)
    print("baseline ppl:", baseline_ppl)

    # approx eigvecs via gradient PCA
    vecs, vals = approx_top_eigvecs(mw, calib, topk=cfg.topk_eig, device=cfg.device)
    print("eigvecs shape", vecs.shape)

    # activation sparsity
    sparsity = compute_activation_sparsity(mw, calib, device=cfg.device)
    print("computed sparsity for", len(sparsity), "modules")

    names, X = build_param_feature_matrix(mw, vecs, sparsity)
    emb, clabels, sil = cluster_and_label(names, X)
    print("UMAP emb shape", emb.shape, "silhouette", sil)

    name_labels = partition_rule(names, X, vecs, sparsity)
    # group names per label
    groups = { 'Wfunc': [], 'Wsens': [], 'Wboth': [] }
    for n, lab in name_labels.items():
        groups[lab].append(n)
    print("group sizes:", {k: len(v) for k, v in groups.items()})

    # run noise injection small sweep
    results = []
    for lab in ['Wfunc', 'Wsens', 'Wboth']:
        target_names = set(groups[lab])
        mask = {n: lab for n in target_names}
        for sigma in cfg.noise_sigmas:
            for r in range(cfg.repeats):
                ppl, mia = inject_noise_and_eval(mw, mask, sigma, evals[:50])
                results.append({ 'label': lab, 'sigma': sigma, 'repeat': r, 'ppl': ppl, 'mia': mia })
                print(lab, sigma, r, ppl)

    out_path = os.path.join(cfg.output_dir, 'pilot_results.json')
    save_json(results, out_path)
    print('saved', out_path)
    # save umap scatter
    plt.figure(figsize=(6,6))
    sc = plt.scatter(emb[:,0], emb[:,1], c=clabels, cmap='Spectral', s=8)
    plt.title('UMAP param embedding (pilot)')
    plt.savefig(os.path.join(cfg.output_dir, 'pilot_umap.png'), dpi=200)
    plt.close()
    return out_path

# -----------------------------
# Full experiment orchestration (sketch)
# -----------------------------

def full_experiment():
    # Intended to run after pilot tuning. Same steps but with larger sample sizes,
    # more careful MIA evaluation, and full CSV outputs.
    raise NotImplementedError("请在 pilot 成功后扩展成 full_experiment。可按 pilot_run 中的流程放大样本并实现 MIA 评估模块。")

# -----------------------------
# If executed as script
# -----------------------------
if __name__ == '__main__':
    print('Running pilot run...')
    try:
        pilot_run()
    except Exception as e:
        print('Error during pilot:', e)
        raise

```
